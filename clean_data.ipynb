{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d1fba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "id": "49d054cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kj/dissertation-emews/venv/lib/python3.10/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Unknown extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/home/kj/dissertation-emews/venv/lib/python3.10/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Conditional Formatting extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel(\"data/EMEWS original.xlsx\", engine='openpyxl', header=[1,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40aac7da",
   "metadata": {},
   "source": [
    "### Cleaning Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "id": "85b4b575",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_shape_change(func):\n",
    "    def wrapper(df, *args, **kwargs):\n",
    "        shape_before = df.shape\n",
    "        print(f\"[Before] Shape: {shape_before}\")\n",
    "        \n",
    "        result = func(df, *args, **kwargs)\n",
    "        \n",
    "        if result is not None:\n",
    "            shape_after = result.shape\n",
    "        else:\n",
    "            shape_after = df.shape\n",
    "        print(f\"[After]  Shape: {shape_after}\")\n",
    "        print(f\"[Change] Rows removed: {shape_before[0] - shape_after[0]}, Columns removed: {shape_before[1] - shape_after[1]}\")\n",
    "        \n",
    "        return result\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "id": "dbd57d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "@print_shape_change\n",
    "def clean_missing_data(df, threshold):\n",
    "    # Drop columns with missing value ratio above threshold\n",
    "    missing_ratio = df.isna().mean()\n",
    "    cols_to_drop = missing_ratio[missing_ratio > threshold].index.tolist()\n",
    "    print(\"Dropped columns with > {:.0%} missing values:\".format(threshold), cols_to_drop)\n",
    "    df.drop(columns=cols_to_drop, inplace=True)\n",
    "    \n",
    "    # Drop fully empty columns\n",
    "    empty_cols = df.columns[df.isna().all()].tolist()\n",
    "    df.drop(columns=empty_cols, inplace=True)\n",
    "\n",
    "    # Drop rows where all values from column 2 onward are empty\n",
    "    empty_rows = df.index[df.iloc[:, 2:].isna().all(axis=1)].tolist()\n",
    "    df.drop(index=empty_rows, inplace=True)\n",
    "\n",
    "\n",
    "    df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "id": "eaa3e14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@print_shape_change\n",
    "def remove_total_emews_rows(df):\n",
    "    first_col = df.columns[0]\n",
    "    indices_to_remove = df.index[df[first_col].str.lower().str.startswith('total emews')]\n",
    "    df.drop(index=indices_to_remove, inplace=True)\n",
    "\n",
    "    df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "id": "ccb603fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "@print_shape_change\n",
    "def clean_and_flatten_multiindex(df):\n",
    "    cleaned_cols = []\n",
    "    for lvl0, lvl1 in df.columns:\n",
    "        # If level 0 is unnamed or empty, just use level 1\n",
    "        if 'Unnamed' in str(lvl0) or str(lvl0).strip() == '':\n",
    "            name = str(lvl1)\n",
    "        else:\n",
    "            # Combine both levels\n",
    "            name = f\"{lvl0}_{lvl1}\"\n",
    "        \n",
    "        # Lowercase, strip spaces, replace spaces with _\n",
    "        name = name.lower().strip().replace(' ', '_')\n",
    "        # Replace any -, (, ) with empty string and trailing underscores\n",
    "        name = name.replace('-', '').replace('(', '').replace(')', '').rstrip('_')\n",
    "        \n",
    "        cleaned_cols.append(name)\n",
    "    \n",
    "    df.columns = cleaned_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd49d93b",
   "metadata": {},
   "source": [
    "### Perform Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "id": "82cc76f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Before] Shape: (747, 35)\n",
      "[After]  Shape: (747, 35)\n",
      "[Change] Rows removed: 0, Columns removed: 0\n"
     ]
    }
   ],
   "source": [
    "clean_and_flatten_multiindex(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "id": "ac6f4dd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['zone_b/c_escalations.1', 'zone_b/c_escalations.2',\n",
       "       'decision_density__mews_nurse_zone_a_mwr', 'zone_a', 'zone_b/c',\n",
       "       'total', 'decision_density__cnm_unnamed:_28_level_1',\n",
       "       'decision_density__cnm_dd_cnm',\n",
       "       'decision_density__cnm_daily_patient_numbers',\n",
       "       'decision_density__cnm_skill_mix_senior_both',\n",
       "       'mandarin_skill_mix_senior', 'white_skill_mix_senior',\n",
       "       'green_skill_mix_standard'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 545,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns[df.isna().mean() > 0.95]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "id": "79dd677e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Before] Shape: (747, 35)\n",
      "Dropped columns with > 95% missing values: ['zone_b/c_escalations.1', 'zone_b/c_escalations.2', 'decision_density__mews_nurse_zone_a_mwr', 'zone_a', 'zone_b/c', 'total', 'decision_density__cnm_unnamed:_28_level_1', 'decision_density__cnm_dd_cnm', 'decision_density__cnm_daily_patient_numbers', 'decision_density__cnm_skill_mix_senior_both', 'mandarin_skill_mix_senior', 'white_skill_mix_senior', 'green_skill_mix_standard']\n",
      "[After]  Shape: (643, 22)\n",
      "[Change] Rows removed: 104, Columns removed: 13\n"
     ]
    }
   ],
   "source": [
    "clean_missing_data(df=df, threshold=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "id": "3301849f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Before] Shape: (643, 22)\n",
      "[After]  Shape: (599, 22)\n",
      "[Change] Rows removed: 44, Columns removed: 0\n"
     ]
    }
   ],
   "source": [
    "remove_total_emews_rows(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "id": "94347ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume each EMEWS set takes 10 mins\n",
    "# Shift time = 11 hours = 660 minutes\n",
    "\n",
    "# EMEWS per nurse per day = 660 minutes / 10 minutes per EMEWS = 66\n",
    "\n",
    "# df[\"nurses_required_for_emews\"] = df[\"total_number_of_emews\"] / 66"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "id": "2deff4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/EMEWS cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ddda2b9",
   "metadata": {},
   "source": [
    "### Cleaning Non-Numeric and Whitespace-Only Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "id": "8e19b639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify columns containing empty/whitespace-only strings\n",
    "cols_with_missing = [\n",
    "    col for col in df.columns\n",
    "    if df[col].astype(str).str.match(r'^\\s*$').any()\n",
    "]\n",
    "\n",
    "for col in cols_with_missing:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "still_non_numeric_cols = set(df.columns) - set(df.select_dtypes(include='number').columns) - {'date', 'day'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "id": "5261cd9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-numeric values in column 'zone_a_mwr_escalations': [nan '0 - stopped 16.00' '2 - commenced 15.00']\n",
      "Replace map: {'0 - stopped 16.00': '0', '2 - commenced 15.00': '2'}\n",
      "\n",
      "Non-numeric values in column 'zone_b/c_sets_of_emews': [nan '7 *commenced @ 14.00' '43 *stopped 16.40' '51 *commenced 10.44am'\n",
      " '64 - paused for 2hrs']\n",
      "Replace map: {'7 *commenced @ 14.00': '7', '43 *stopped 16.40': '43', '51 *commenced 10.44am': '51', '64 - paused for 2hrs': '64'}\n",
      "\n",
      "Non-numeric values in column 'zone_a__sets_of_emews': [nan '81 - stopped @6pm' '68 -commenced 12md']\n",
      "Replace map: {'81 - stopped @6pm': '81', '68 -commenced 12md': '68'}\n",
      "\n",
      "Non-numeric values in column 'zone_a_mwr_deescalations': [nan 'Nurse redeployed' 'Nurse Re-deployed' 'stopped at 2']\n",
      "Replace map: {'Nurse redeployed': nan, 'Nurse Re-deployed': nan, 'stopped at 2': nan}\n",
      "\n",
      "Non-numeric values in column 'zone_a__cat_3': [nan]\n",
      "Replace map: {}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for col in still_non_numeric_cols:\n",
    "    non_numeric_values = df[col][pd.to_numeric(df[col], errors='coerce').isna()]\n",
    "    print(f\"Non-numeric values in column '{col}': {non_numeric_values.unique()}\")\n",
    "\n",
    "    replace_map = {}\n",
    "\n",
    "    for val in list(non_numeric_values.unique()):\n",
    "        # Use regex to check if string starts with digits\n",
    "        if pd.notna(val):\n",
    "            match = re.match(r'^(\\d+)', val)\n",
    "            if match:\n",
    "                replace_map[val] = match.group(1)\n",
    "            else:\n",
    "                replace_map[val] = np.nan\n",
    "\n",
    "    print(f\"Replace map: {replace_map}\", end='\\n\\n')\n",
    "    df[col] = df[col].replace(replace_map)\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "id": "5839d9c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Columns in Dataframe: 22\n",
      "Numeric Columns in Dataframe(should be total - 2(date cols):20\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total Number of Columns in Dataframe: {len(df.columns)}\")\n",
    "print(f\"Numeric Columns in Dataframe(should be total - 2(date cols):{len(df.select_dtypes(include='number').columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3670c0ff",
   "metadata": {},
   "source": [
    "### Adjusting Day and Date Columns to Handle AM/PM Time Information for Duplicate Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "id": "df56176b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whitespace removed from 51 cells in column 'day'.\n"
     ]
    }
   ],
   "source": [
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "df['day'] = df['day'].str.lower()\n",
    "original_values = df['day'].copy()\n",
    "df['day'] = df['day'].str.strip()\n",
    "num_cells_stripped = ((original_values != df['day']) & original_values.notna()).sum()\n",
    "\n",
    "print(f\"Whitespace removed from {num_cells_stripped} cells in column 'day'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "id": "c8ba1af4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of duplicated dates: 568\n",
      "Starting date: 2024-01-22 00:00:00, Starting Index: 17\n",
      "Rows == dup_dates count + start idx --> False\n"
     ]
    }
   ],
   "source": [
    "df['am_pm'] = df['day'].str.extract(r'(am|pm)$', expand=False).fillna('am')\n",
    "dup_dates = df['date'][df['date'].duplicated(keep=False)]\n",
    "\n",
    "print(f\"Count of duplicated dates: {dup_dates.count()}\")\n",
    "print(f\"Starting date: {dup_dates.iloc[0]}, Starting Index: {dup_dates.index[0]}\")\n",
    "print(f\"Rows == dup_dates count + start idx --> {df.shape[0] == dup_dates.count() + dup_dates.index[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "id": "38ba2910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuity breaks between these index pairs:\n",
      "Gap between 256 and 261\n",
      "Gap between 270 and 275\n",
      "Gap between 348 and 351\n",
      "Gap between 396 and 399\n",
      "Gap between 496 and 499\n"
     ]
    }
   ],
   "source": [
    "indices = dup_dates.index.to_list()\n",
    "\n",
    "# Find gaps where continuity breaks\n",
    "break_points = [(indices[i], indices[i+1]) for i in range(len(indices)-1) if indices[i+1] != indices[i] + 1]\n",
    "\n",
    "print(\"Continuity breaks between these index pairs:\")\n",
    "for start_idx, end_idx in break_points:\n",
    "    print(f\"Gap between {start_idx} and {end_idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "id": "001c9541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Values in the gap ranges:\n",
      "\n",
      "Values between indices 257 and 260:\n",
      "257   2024-05-21\n",
      "258   2014-05-21\n",
      "259   2014-05-22\n",
      "260   2024-05-22\n",
      "Name: date, dtype: datetime64[ns]\n",
      "----------------------------------------\n",
      "Values between indices 271 and 274:\n",
      "271   2024-05-28\n",
      "272   2014-05-28\n",
      "273   2014-05-29\n",
      "274   2024-05-29\n",
      "Name: date, dtype: datetime64[ns]\n",
      "----------------------------------------\n",
      "Values between indices 349 and 350:\n",
      "349   2014-07-06\n",
      "350   2024-07-06\n",
      "Name: date, dtype: datetime64[ns]\n",
      "----------------------------------------\n",
      "Values between indices 397 and 398:\n",
      "397   2024-07-30\n",
      "398   2014-07-30\n",
      "Name: date, dtype: datetime64[ns]\n",
      "----------------------------------------\n",
      "Values between indices 497 and 498:\n",
      "497   2024-09-18\n",
      "498   2014-09-18\n",
      "Name: date, dtype: datetime64[ns]\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nValues in the gap ranges:\", end='\\n\\n')\n",
    "\n",
    "for start_idx, end_idx in break_points:\n",
    "    # The gap range is indices between start_idx+1 and end_idx-1 (exclusive)\n",
    "    gap_range = range(start_idx + 1, end_idx)\n",
    "    values_in_gap = df.iloc[gap_range]['date']\n",
    "    print(f\"Values between indices {start_idx+1} and {end_idx-1}:\")\n",
    "    print(values_in_gap)\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "id": "d59197db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are all indices continuous --> True\n",
      "Count of duplicated dates: 582\n",
      "Starting date: 2024-01-22 00:00:00, Starting Index: 17\n",
      "Rows == dup_dates count + start idx --> True\n"
     ]
    }
   ],
   "source": [
    "# Update year from 2014 to 2024 in 'date' column\n",
    "mask_2014 = df['date'].dt.year == 2014\n",
    "df.loc[mask_2014, 'date'] = df.loc[mask_2014, 'date'].apply(lambda dt: dt.replace(year=2024))\n",
    "\n",
    "dup_dates = df['date'][df['date'].duplicated(keep=False)]\n",
    "indices = dup_dates.index.to_list()\n",
    "\n",
    "# Check if duplicated date indices are continuous\n",
    "are_continuous = all(b == a + 1 for a, b in zip(indices, indices[1:]))\n",
    "print(f\"Are all indices continuous --> {are_continuous}\")\n",
    "\n",
    "print(f\"Count of duplicated dates: {dup_dates.count()}\")\n",
    "print(f\"Starting date: {dup_dates.iloc[0]}, Starting Index: {dup_dates.index[0]}\")\n",
    "print(f\"Rows == dup_dates count + start idx --> {df.shape[0] == dup_dates.count() + dup_dates.index[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "id": "e4ccf61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_dup = df['date'].isin(dup_dates)\n",
    "\n",
    "# Remove 'am' or 'pm' suffix from 'day' column only for duplicated date rows\n",
    "df.loc[mask_dup, 'day'] = df.loc[mask_dup, 'day'].str.replace(r'\\s*(am|pm)$', '', regex=True)\n",
    "\n",
    "# For duplicated date rows with 'pm', add 12 hours to 'date' to represent afternoon time\n",
    "df.loc[mask_dup & (df['am_pm'] == 'pm'), 'date'] += pd.Timedelta(hours=12)\n",
    "\n",
    "df.drop(columns=['am_pm'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "id": "e2f0ad9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['thursday', 'friday', 'saturday', 'sunday', 'monday', 'tuesday',\n",
       "       'wednesday', 'wenesday', 'wedneday', 'tue'], dtype=object)"
      ]
     },
     "execution_count": 559,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['day'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "id": "87576009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['thursday', 'friday', 'saturday', 'sunday', 'monday', 'tuesday',\n",
       "       'wednesday'], dtype=object)"
      ]
     },
     "execution_count": 560,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fix_map = {\n",
    "    'tue': 'tuesday',\n",
    "    'wenesday': 'wednesday',\n",
    "    'wedneday': 'wednesday'\n",
    "}\n",
    "\n",
    "df['day'] = df['day'].replace(fix_map)\n",
    "df['day'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6e947d",
   "metadata": {},
   "source": [
    "### Save the cleaned file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "id": "92e29c17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "day                          0.000000\n",
       "date                         0.000000\n",
       "total_number_of_patients     0.333890\n",
       "total_number_of_emews        0.333890\n",
       "zone_a_mwr_patients         42.904841\n",
       "zone_a_mwr_cat_3            43.071786\n",
       "zone_a_mwr_cat_4            43.071786\n",
       "zone_a_mwr_sets_of_emews    45.409015\n",
       "zone_a_mwr_deescalations    43.739566\n",
       "zone_a_mwr_escalations      43.405676\n",
       "zone_a__patients             2.671119\n",
       "zone_a__cat_2                2.671119\n",
       "zone_a__cat_3                2.671119\n",
       "zone_a__sets_of_emews        2.671119\n",
       "zone_a__deescalations        2.838063\n",
       "zone_a__escalations          2.838063\n",
       "zone_b/c_patients           86.477462\n",
       "zone_b/c_cat_2              87.312187\n",
       "zone_b/c_cat_3              87.312187\n",
       "zone_b/c_sets_of_emews      86.477462\n",
       "zone_b/c_deescalations      86.644407\n",
       "zone_b/c_escalations        86.644407\n",
       "dtype: float64"
      ]
     },
     "execution_count": 561,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().mean() * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "id": "da207066",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data/EMEWS_cleaned_with_nan.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
