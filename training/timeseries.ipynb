{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3a8c7b1",
   "metadata": {},
   "source": [
    "## 1. Configuration\n",
    "\n",
    "Set the paths and flags for the modeling process below. \n",
    "- `TRAIN_NEW_MODELS`: Set to `True` to run training and tuning. Set to `False` to load existing models.\n",
    "- `INPUT_DIR`: The directory where your source data CSV is located.\n",
    "- `DATAFRAME_NAME`: The name of your CSV file (without the `.csv` extension).\n",
    "- `OUTPUT_DIR_WINDOWS`: The root folder on your Windows drive where model pipelines will be saved. The path is written in WSL format (e.g., `/mnt/d/` for the `D:` drive)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "config-cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating directory for base models: /mnt/d/EMEWS_ML_Pipelines_Output/timeseries/mean_df/base_models\n",
      "Creating directory for tuned models: /mnt/d/EMEWS_ML_Pipelines_Output/timeseries/mean_df/tuned_models\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Set to True to run the full training and tuning process.\n",
    "# Set to False to load pre-existing models from the output directory.\n",
    "TRAIN_NEW_MODELS = True\n",
    "\n",
    "# PATHS\n",
    "INPUT_DIR = os.path.join('..', 'data', 'upsampled')\n",
    "DATAFRAME_NAME = 'mean_df' # Name of the .csv file without the extension\n",
    "\n",
    "# Output directory for saving model pipelines (WSL format for Windows D: drive)\n",
    "# This path corresponds to D:\\ML_Pipelines in Windows\n",
    "OUTPUT_ROOT_DIR_WINDOWS = '/mnt/d/EMEWS_ML_Pipelines_Output/timeseries'\n",
    "DATAFRAME_SPECIFIC_PATH = os.path.join(OUTPUT_ROOT_DIR_WINDOWS, DATAFRAME_NAME)\n",
    "BASE_MODEL_PATH = os.path.join(DATAFRAME_SPECIFIC_PATH, 'base_models')\n",
    "TUNED_MODEL_PATH = os.path.join(DATAFRAME_SPECIFIC_PATH, 'tuned_models')\n",
    "\n",
    "# Create directories if they don't exist\n",
    "if TRAIN_NEW_MODELS:\n",
    "    print(f\"Creating directory for base models: {BASE_MODEL_PATH}\")\n",
    "    os.makedirs(BASE_MODEL_PATH, exist_ok=True)\n",
    "    print(f\"Creating directory for tuned models: {TUNED_MODEL_PATH}\")\n",
    "    os.makedirs(TUNED_MODEL_PATH, exist_ok=True)\n",
    "else:\n",
    "    print(\"TRAIN_NEW_MODELS is False. Will attempt to load existing models.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b1d3a4",
   "metadata": {},
   "source": [
    "## 2. Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "861da9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pycaret.time_series import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c67c388",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(INPUT_DIR, f'{DATAFRAME_NAME}.csv'),  parse_dates=['date'])\n",
    "df.set_index('date', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384e06d7",
   "metadata": {},
   "source": [
    "## 3. Pycaret Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f27cedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_COLUMN = 'total_number_of_patients'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be1f4dd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_a3db8_row25_col1 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_a3db8\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_a3db8_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th id=\"T_a3db8_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_a3db8_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_a3db8_row0_col0\" class=\"data row0 col0\" >session_id</td>\n",
       "      <td id=\"T_a3db8_row0_col1\" class=\"data row0 col1\" >123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a3db8_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_a3db8_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_a3db8_row1_col1\" class=\"data row1 col1\" >total_number_of_patients</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a3db8_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_a3db8_row2_col0\" class=\"data row2 col0\" >Approach</td>\n",
       "      <td id=\"T_a3db8_row2_col1\" class=\"data row2 col1\" >Univariate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a3db8_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_a3db8_row3_col0\" class=\"data row3 col0\" >Exogenous Variables</td>\n",
       "      <td id=\"T_a3db8_row3_col1\" class=\"data row3 col1\" >Present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a3db8_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_a3db8_row4_col0\" class=\"data row4 col0\" >Original data shape</td>\n",
       "      <td id=\"T_a3db8_row4_col1\" class=\"data row4 col1\" >(618, 20)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a3db8_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_a3db8_row5_col0\" class=\"data row5 col0\" >Transformed data shape</td>\n",
       "      <td id=\"T_a3db8_row5_col1\" class=\"data row5 col1\" >(618, 20)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a3db8_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_a3db8_row6_col0\" class=\"data row6 col0\" >Transformed train set shape</td>\n",
       "      <td id=\"T_a3db8_row6_col1\" class=\"data row6 col1\" >(558, 20)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a3db8_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_a3db8_row7_col0\" class=\"data row7 col0\" >Transformed test set shape</td>\n",
       "      <td id=\"T_a3db8_row7_col1\" class=\"data row7 col1\" >(60, 20)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a3db8_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_a3db8_row8_col0\" class=\"data row8 col0\" >Rows with missing values</td>\n",
       "      <td id=\"T_a3db8_row8_col1\" class=\"data row8 col1\" >0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a3db8_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_a3db8_row9_col0\" class=\"data row9 col0\" >Fold Generator</td>\n",
       "      <td id=\"T_a3db8_row9_col1\" class=\"data row9 col1\" >ExpandingWindowSplitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a3db8_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_a3db8_row10_col0\" class=\"data row10 col0\" >Fold Number</td>\n",
       "      <td id=\"T_a3db8_row10_col1\" class=\"data row10 col1\" >3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a3db8_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_a3db8_row11_col0\" class=\"data row11 col0\" >Enforce Prediction Interval</td>\n",
       "      <td id=\"T_a3db8_row11_col1\" class=\"data row11 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a3db8_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_a3db8_row12_col0\" class=\"data row12 col0\" >Splits used for hyperparameters</td>\n",
       "      <td id=\"T_a3db8_row12_col1\" class=\"data row12 col1\" >all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a3db8_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_a3db8_row13_col0\" class=\"data row13 col0\" >User Defined Seasonal Period(s)</td>\n",
       "      <td id=\"T_a3db8_row13_col1\" class=\"data row13 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a3db8_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_a3db8_row14_col0\" class=\"data row14 col0\" >Ignore Seasonality Test</td>\n",
       "      <td id=\"T_a3db8_row14_col1\" class=\"data row14 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a3db8_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_a3db8_row15_col0\" class=\"data row15 col0\" >Seasonality Detection Algo</td>\n",
       "      <td id=\"T_a3db8_row15_col1\" class=\"data row15 col1\" >auto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a3db8_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_a3db8_row16_col0\" class=\"data row16 col0\" >Max Period to Consider</td>\n",
       "      <td id=\"T_a3db8_row16_col1\" class=\"data row16 col1\" >60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a3db8_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_a3db8_row17_col0\" class=\"data row17 col0\" >Seasonal Period(s) Tested</td>\n",
       "      <td id=\"T_a3db8_row17_col1\" class=\"data row17 col1\" >[26, 24]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a3db8_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_a3db8_row18_col0\" class=\"data row18 col0\" >Significant Seasonal Period(s)</td>\n",
       "      <td id=\"T_a3db8_row18_col1\" class=\"data row18 col1\" >[26, 24]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a3db8_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_a3db8_row19_col0\" class=\"data row19 col0\" >Significant Seasonal Period(s) without Harmonics</td>\n",
       "      <td id=\"T_a3db8_row19_col1\" class=\"data row19 col1\" >[26, 24]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a3db8_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "      <td id=\"T_a3db8_row20_col0\" class=\"data row20 col0\" >Remove Harmonics</td>\n",
       "      <td id=\"T_a3db8_row20_col1\" class=\"data row20 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a3db8_level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
       "      <td id=\"T_a3db8_row21_col0\" class=\"data row21 col0\" >Harmonics Order Method</td>\n",
       "      <td id=\"T_a3db8_row21_col1\" class=\"data row21 col1\" >harmonic_max</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a3db8_level0_row22\" class=\"row_heading level0 row22\" >22</th>\n",
       "      <td id=\"T_a3db8_row22_col0\" class=\"data row22 col0\" >Num Seasonalities to Use</td>\n",
       "      <td id=\"T_a3db8_row22_col1\" class=\"data row22 col1\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a3db8_level0_row23\" class=\"row_heading level0 row23\" >23</th>\n",
       "      <td id=\"T_a3db8_row23_col0\" class=\"data row23 col0\" >All Seasonalities to Use</td>\n",
       "      <td id=\"T_a3db8_row23_col1\" class=\"data row23 col1\" >[26]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a3db8_level0_row24\" class=\"row_heading level0 row24\" >24</th>\n",
       "      <td id=\"T_a3db8_row24_col0\" class=\"data row24 col0\" >Primary Seasonality</td>\n",
       "      <td id=\"T_a3db8_row24_col1\" class=\"data row24 col1\" >26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a3db8_level0_row25\" class=\"row_heading level0 row25\" >25</th>\n",
       "      <td id=\"T_a3db8_row25_col0\" class=\"data row25 col0\" >Seasonality Present</td>\n",
       "      <td id=\"T_a3db8_row25_col1\" class=\"data row25 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a3db8_level0_row26\" class=\"row_heading level0 row26\" >26</th>\n",
       "      <td id=\"T_a3db8_row26_col0\" class=\"data row26 col0\" >Seasonality Type</td>\n",
       "      <td id=\"T_a3db8_row26_col1\" class=\"data row26 col1\" >mul</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a3db8_level0_row27\" class=\"row_heading level0 row27\" >27</th>\n",
       "      <td id=\"T_a3db8_row27_col0\" class=\"data row27 col0\" >Target Strictly Positive</td>\n",
       "      <td id=\"T_a3db8_row27_col1\" class=\"data row27 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a3db8_level0_row28\" class=\"row_heading level0 row28\" >28</th>\n",
       "      <td id=\"T_a3db8_row28_col0\" class=\"data row28 col0\" >Target White Noise</td>\n",
       "      <td id=\"T_a3db8_row28_col1\" class=\"data row28 col1\" >No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a3db8_level0_row29\" class=\"row_heading level0 row29\" >29</th>\n",
       "      <td id=\"T_a3db8_row29_col0\" class=\"data row29 col0\" >Recommended d</td>\n",
       "      <td id=\"T_a3db8_row29_col1\" class=\"data row29 col1\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a3db8_level0_row30\" class=\"row_heading level0 row30\" >30</th>\n",
       "      <td id=\"T_a3db8_row30_col0\" class=\"data row30 col0\" >Recommended Seasonal D</td>\n",
       "      <td id=\"T_a3db8_row30_col1\" class=\"data row30 col1\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a3db8_level0_row31\" class=\"row_heading level0 row31\" >31</th>\n",
       "      <td id=\"T_a3db8_row31_col0\" class=\"data row31 col0\" >Preprocess</td>\n",
       "      <td id=\"T_a3db8_row31_col1\" class=\"data row31 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a3db8_level0_row32\" class=\"row_heading level0 row32\" >32</th>\n",
       "      <td id=\"T_a3db8_row32_col0\" class=\"data row32 col0\" >CPU Jobs</td>\n",
       "      <td id=\"T_a3db8_row32_col1\" class=\"data row32 col1\" >-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a3db8_level0_row33\" class=\"row_heading level0 row33\" >33</th>\n",
       "      <td id=\"T_a3db8_row33_col0\" class=\"data row33 col0\" >Use GPU</td>\n",
       "      <td id=\"T_a3db8_row33_col1\" class=\"data row33 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a3db8_level0_row34\" class=\"row_heading level0 row34\" >34</th>\n",
       "      <td id=\"T_a3db8_row34_col0\" class=\"data row34 col0\" >Log Experiment</td>\n",
       "      <td id=\"T_a3db8_row34_col1\" class=\"data row34 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a3db8_level0_row35\" class=\"row_heading level0 row35\" >35</th>\n",
       "      <td id=\"T_a3db8_row35_col0\" class=\"data row35 col0\" >Experiment Name</td>\n",
       "      <td id=\"T_a3db8_row35_col1\" class=\"data row35 col1\" >ts-default-name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a3db8_level0_row36\" class=\"row_heading level0 row36\" >36</th>\n",
       "      <td id=\"T_a3db8_row36_col0\" class=\"data row36 col0\" >USI</td>\n",
       "      <td id=\"T_a3db8_row36_col1\" class=\"data row36 col1\" >dd63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x764fa11bd660>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "exp = TSForecastingExperiment()\n",
    "exp.setup(data=df, fh=60, target=TARGET_COLUMN, session_id=123);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a0b1c2",
   "metadata": {},
   "source": [
    "## 4. Model Training or Loading\n",
    "\n",
    "Based on the `TRAIN_NEW_MODELS` flag, this section will either train and save new models or load existing ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45a5f207",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "train-or-load",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Model Training and Tuning\n",
      "\n",
      "--- Processing Model: arima ---\n",
      "Creating base model: arima\n",
      "Saving base model to: /mnt/d/EMEWS_ML_Pipelines_Output/timeseries/mean_df/base_models/arima\n",
      "Transformation Pipeline and Model Successfully Saved\n",
      "Tuning model: arima\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_33bc9_row3_col0, #T_33bc9_row3_col1, #T_33bc9_row3_col2, #T_33bc9_row3_col3, #T_33bc9_row3_col4, #T_33bc9_row3_col5, #T_33bc9_row3_col6, #T_33bc9_row3_col7 {\n",
       "  background: yellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_33bc9\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_33bc9_level0_col0\" class=\"col_heading level0 col0\" >cutoff</th>\n",
       "      <th id=\"T_33bc9_level0_col1\" class=\"col_heading level0 col1\" >MASE</th>\n",
       "      <th id=\"T_33bc9_level0_col2\" class=\"col_heading level0 col2\" >RMSSE</th>\n",
       "      <th id=\"T_33bc9_level0_col3\" class=\"col_heading level0 col3\" >MAE</th>\n",
       "      <th id=\"T_33bc9_level0_col4\" class=\"col_heading level0 col4\" >RMSE</th>\n",
       "      <th id=\"T_33bc9_level0_col5\" class=\"col_heading level0 col5\" >MAPE</th>\n",
       "      <th id=\"T_33bc9_level0_col6\" class=\"col_heading level0 col6\" >SMAPE</th>\n",
       "      <th id=\"T_33bc9_level0_col7\" class=\"col_heading level0 col7\" >R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_33bc9_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_33bc9_row0_col0\" class=\"data row0 col0\" >2024-07-10 12:00</td>\n",
       "      <td id=\"T_33bc9_row0_col1\" class=\"data row0 col1\" >0.1640</td>\n",
       "      <td id=\"T_33bc9_row0_col2\" class=\"data row0 col2\" >0.2394</td>\n",
       "      <td id=\"T_33bc9_row0_col3\" class=\"data row0 col3\" >3.0310</td>\n",
       "      <td id=\"T_33bc9_row0_col4\" class=\"data row0 col4\" >5.8664</td>\n",
       "      <td id=\"T_33bc9_row0_col5\" class=\"data row0 col5\" >0.0757</td>\n",
       "      <td id=\"T_33bc9_row0_col6\" class=\"data row0 col6\" >0.0966</td>\n",
       "      <td id=\"T_33bc9_row0_col7\" class=\"data row0 col7\" >0.8956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_33bc9_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_33bc9_row1_col0\" class=\"data row1 col0\" >2024-08-09 12:00</td>\n",
       "      <td id=\"T_33bc9_row1_col1\" class=\"data row1 col1\" >0.2749</td>\n",
       "      <td id=\"T_33bc9_row1_col2\" class=\"data row1 col2\" >0.3239</td>\n",
       "      <td id=\"T_33bc9_row1_col3\" class=\"data row1 col3\" >5.1984</td>\n",
       "      <td id=\"T_33bc9_row1_col4\" class=\"data row1 col4\" >8.0942</td>\n",
       "      <td id=\"T_33bc9_row1_col5\" class=\"data row1 col5\" >0.1347</td>\n",
       "      <td id=\"T_33bc9_row1_col6\" class=\"data row1 col6\" >0.1609</td>\n",
       "      <td id=\"T_33bc9_row1_col7\" class=\"data row1 col7\" >0.8693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_33bc9_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_33bc9_row2_col0\" class=\"data row2 col0\" >2024-09-08 12:00</td>\n",
       "      <td id=\"T_33bc9_row2_col1\" class=\"data row2 col1\" >0.2332</td>\n",
       "      <td id=\"T_33bc9_row2_col2\" class=\"data row2 col2\" >0.2320</td>\n",
       "      <td id=\"T_33bc9_row2_col3\" class=\"data row2 col3\" >4.5613</td>\n",
       "      <td id=\"T_33bc9_row2_col4\" class=\"data row2 col4\" >5.9551</td>\n",
       "      <td id=\"T_33bc9_row2_col5\" class=\"data row2 col5\" >0.1106</td>\n",
       "      <td id=\"T_33bc9_row2_col6\" class=\"data row2 col6\" >0.1122</td>\n",
       "      <td id=\"T_33bc9_row2_col7\" class=\"data row2 col7\" >0.9223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_33bc9_level0_row3\" class=\"row_heading level0 row3\" >Mean</th>\n",
       "      <td id=\"T_33bc9_row3_col0\" class=\"data row3 col0\" >NaT</td>\n",
       "      <td id=\"T_33bc9_row3_col1\" class=\"data row3 col1\" >0.2240</td>\n",
       "      <td id=\"T_33bc9_row3_col2\" class=\"data row3 col2\" >0.2651</td>\n",
       "      <td id=\"T_33bc9_row3_col3\" class=\"data row3 col3\" >4.2636</td>\n",
       "      <td id=\"T_33bc9_row3_col4\" class=\"data row3 col4\" >6.6386</td>\n",
       "      <td id=\"T_33bc9_row3_col5\" class=\"data row3 col5\" >0.1070</td>\n",
       "      <td id=\"T_33bc9_row3_col6\" class=\"data row3 col6\" >0.1232</td>\n",
       "      <td id=\"T_33bc9_row3_col7\" class=\"data row3 col7\" >0.8957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_33bc9_level0_row4\" class=\"row_heading level0 row4\" >SD</th>\n",
       "      <td id=\"T_33bc9_row4_col0\" class=\"data row4 col0\" >NaT</td>\n",
       "      <td id=\"T_33bc9_row4_col1\" class=\"data row4 col1\" >0.0457</td>\n",
       "      <td id=\"T_33bc9_row4_col2\" class=\"data row4 col2\" >0.0417</td>\n",
       "      <td id=\"T_33bc9_row4_col3\" class=\"data row4 col3\" >0.9095</td>\n",
       "      <td id=\"T_33bc9_row4_col4\" class=\"data row4 col4\" >1.0299</td>\n",
       "      <td id=\"T_33bc9_row4_col5\" class=\"data row4 col5\" >0.0242</td>\n",
       "      <td id=\"T_33bc9_row4_col6\" class=\"data row4 col6\" >0.0274</td>\n",
       "      <td id=\"T_33bc9_row4_col7\" class=\"data row4 col7\" >0.0217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x764fa037fd60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  3.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving tuned model to: /mnt/d/EMEWS_ML_Pipelines_Output/timeseries/mean_df/tuned_models/arima\n",
      "Transformation Pipeline and Model Successfully Saved\n",
      "\n",
      "--- Processing Model: auto_arima ---\n",
      "Creating base model: auto_arima\n",
      "Saving base model to: /mnt/d/EMEWS_ML_Pipelines_Output/timeseries/mean_df/base_models/auto_arima\n",
      "Transformation Pipeline and Model Successfully Saved\n",
      "Tuning model: auto_arima\n",
      "Auto Arima model already tuned - skipping tuning step.\n",
      "Saving tuned model to: /mnt/d/EMEWS_ML_Pipelines_Output/timeseries/mean_df/tuned_models/auto_arima\n",
      "Transformation Pipeline and Model Successfully Saved\n",
      "\n",
      "Model processing complete.\n",
      "\n",
      "Base models available: ['arima', 'auto_arima']\n",
      "Tuned models available: ['arima', 'auto_arima']\n"
     ]
    }
   ],
   "source": [
    "created_models = {}\n",
    "tuned_models = {}\n",
    "\n",
    "if TRAIN_NEW_MODELS:\n",
    "    print(\"Starting Model Training and Tuning\")\n",
    "    \n",
    "    # Step 1: Compare base models\n",
    "    # exp.compare_models(include=['arima', 'auto_arima'], errors='raise')\n",
    "    # best_models_df = exp.pull()\n",
    "    # model_names_to_process = best_models_df[best_models_df['R2'] > 0.5].sort_values(by='R2', ascending=False)[:5]\n",
    "    model_names_to_process = ['arima', 'auto_arima']\n",
    "    # Step 2: Create, save, and tune base models\n",
    "    for model_name in model_names_to_process:\n",
    "        print(f'\\n--- Processing Model: {model_name} ---')\n",
    "        \n",
    "        # Create base model\n",
    "        print(f'Creating base model: {model_name}')\n",
    "        base_model = exp.create_model(model_name, verbose=False)\n",
    "        created_models[model_name] = base_model\n",
    "        \n",
    "        # Save base model pipeline\n",
    "        save_path_base = os.path.join(BASE_MODEL_PATH, model_name)\n",
    "        print(f'Saving base model to: {save_path_base}')\n",
    "        exp.save_model(base_model, save_path_base)\n",
    "        \n",
    "        # Tune model\n",
    "        print(f'Tuning model: {model_name}')\n",
    "\n",
    "        if model_name == 'auto_arima':\n",
    "            print('Auto Arima model already tuned - skipping tuning step.')\n",
    "            tuned_model = base_model\n",
    "        else:\n",
    "            tuned_model = exp.tune_model(base_model)\n",
    "        tuned_models[model_name] = tuned_model\n",
    "        \n",
    "        # Save tuned model pipeline\n",
    "        save_path_tuned = os.path.join(TUNED_MODEL_PATH, model_name)\n",
    "        print(f'Saving tuned model to: {save_path_tuned}')\n",
    "        exp.save_model(tuned_model, save_path_tuned)\n",
    "\n",
    "else:\n",
    "    print(\"--- Loading Existing Models ---\")\n",
    "    # Load base and tuned models if they exist\n",
    "    if os.path.exists(BASE_MODEL_PATH):\n",
    "        model_names_to_process = [os.path.splitext(f)[0] for f in os.listdir(BASE_MODEL_PATH) if f.endswith('.pkl')]\n",
    "        print(f\"Found models in {BASE_MODEL_PATH}: {model_names_to_process}\")\n",
    "    else:\n",
    "        print(f\"ERROR: Base model directory not found at {BASE_MODEL_PATH}. Cannot load models.\")\n",
    "        model_names_to_process = []\n",
    "    \n",
    "    for name in model_names_to_process:\n",
    "        base_path = os.path.join(BASE_MODEL_PATH, name)\n",
    "        tuned_path = os.path.join(TUNED_MODEL_PATH, name)\n",
    "        \n",
    "        # Load Base Model\n",
    "        if os.path.exists(f'{base_path}.pkl'):\n",
    "            print(f'Loading base model: {name} from {base_path}')\n",
    "            created_models[name] = exp.load_model(base_path, verbose=False)\n",
    "        else:\n",
    "            print(f'WARNING: Base model for {name} not found at {base_path}.pkl')\n",
    "            \n",
    "        # Load Tuned Model\n",
    "        if os.path.exists(f'{tuned_path}.pkl'):\n",
    "            print(f'Loading tuned model: {name} from {tuned_path}')\n",
    "            tuned_models[name] = exp.load_model(tuned_path, verbose=False)\n",
    "        else:\n",
    "            print(f'WARNING: Tuned model for {name} not found at {tuned_path}.pkl')\n",
    "\n",
    "print(\"\\nModel processing complete.\")\n",
    "print(f\"\\nBase models available: {list(created_models.keys())}\")\n",
    "print(f\"Tuned models available: {list(tuned_models.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fb028d",
   "metadata": {},
   "source": [
    "## 5. Custom Metrics and Final Predictions\n",
    "This section defines and adds custom metrics for evaluating predictions on the hold-out set, then generates and saves the final performance metrics to an Excel file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ec1b7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "def r2_rounded(y_true, y_pred):\n",
    "    \"\"\"Calculates R2 score after rounding predictions to the nearest whole number.\"\"\"\n",
    "    return r2_score(y_true, np.round(y_pred))\n",
    "\n",
    "def rmse_rounded(y_true, y_pred):\n",
    "    \"\"\"Calculates RMSE after rounding predictions to the nearest whole number.\"\"\"\n",
    "    return np.sqrt(mean_squared_error(y_true, np.round(y_pred)))\n",
    "\n",
    "def r2_ceil(y_true, y_pred):\n",
    "    \"\"\"Calculates R2 score after ceiling predictions to the nearest whole number.\"\"\"\n",
    "    return r2_score(y_true, np.ceil(y_pred))\n",
    "\n",
    "def rmse_ceil(y_true, y_pred):\n",
    "    \"\"\"Calculates RMSE after ceiling predictions to the nearest whole number.\"\"\"\n",
    "    return np.sqrt(mean_squared_error(y_true, np.ceil(y_pred)))\n",
    "\n",
    "def mae_rounded(y_true, y_pred):\n",
    "    \"\"\"Calculates MAE after rounding predictions to the nearest whole number.\"\"\"\n",
    "    return mean_absolute_error(y_true, np.round(y_pred))\n",
    "\n",
    "def mae_ceil(y_true, y_pred):\n",
    "    \"\"\"Calculates MAE after ceiling predictions to the nearest whole number.\"\"\"\n",
    "    return mean_absolute_error(y_true, np.ceil(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6bcddf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    exp.add_metric('R2_Rounded', 'R2_RND', r2_rounded, greater_is_better=True)\n",
    "    exp.add_metric('RMSE_Rounded', 'RMSE_RND', rmse_rounded, greater_is_better=False)\n",
    "    exp.add_metric('MAE_Rounded', 'MAE_RND', mae_rounded, greater_is_better=False)\n",
    "    exp.add_metric('R2_Ceil', 'R2_CEIL', r2_ceil, greater_is_better=True)\n",
    "    exp.add_metric('RMSE_Ceil', 'RMSE_CEIL', rmse_ceil, greater_is_better=False)\n",
    "    exp.add_metric('MAE_Ceil', 'MAE_CEIL', mae_ceil, greater_is_better=False)\n",
    "except ValueError:\n",
    "    print(\"Metrics may have already been added in this session.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "generate-predictions",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions for base model: arima\n",
      "Generating predictions for base model: auto_arima\n",
      "Generating predictions for tuned model: arima\n",
      "Generating predictions for tuned model: auto_arima\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions for base models\n",
    "holdout_predictions_metric = {}\n",
    "if not created_models:\n",
    "    print(\"No base models available to make predictions.\")\n",
    "else:\n",
    "    for model_name, model_object in created_models.items():\n",
    "        print(f\"Generating predictions for base model: {model_name}\")\n",
    "        exp.predict_model(model_object, verbose=False)\n",
    "        holdout_predictions_metric[model_name] = exp.pull()\n",
    "\n",
    "# Generate predictions for tuned models\n",
    "tuning_predictions_metric = {}\n",
    "if not tuned_models:\n",
    "    print(\"No tuned models available to make predictions.\")\n",
    "else:\n",
    "    for model_name, model_object in tuned_models.items():\n",
    "        print(f\"Generating predictions for tuned model: {model_name}\")\n",
    "        exp.predict_model(model_object, verbose=False)\n",
    "        tuning_predictions_metric[model_name] = exp.pull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18c0c8ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving performance metrics to: /mnt/d/EMEWS_ML_Pipelines_Output/timeseries/mean_df/model_performance_metrics.xlsx\n",
      "\n",
      "--- Base Model Holdout Predictions ---\n",
      "        Model    MASE   RMSSE     MAE    RMSE    MAPE   SMAPE      R2  R2_RND  RMSE_RND  MAE_RND  R2_CEIL  RMSE_CEIL  MAE_CEIL\n",
      "1  Auto ARIMA  0.1634  0.1729  3.2829  4.5522  0.0778  0.0745  0.9503  0.9500    4.5662   3.2833   0.9471     4.6957    3.3833\n",
      "0       ARIMA  0.1851  0.1818  3.7196  4.7857  0.0753  0.0751  0.9451  0.9459    4.7487   3.6833   0.9437     4.8460    3.7500\n",
      "\n",
      "--- Tuned Model Holdout Predictions ---\n",
      "        Model    MASE   RMSSE     MAE    RMSE    MAPE   SMAPE      R2  R2_RND  RMSE_RND  MAE_RND  R2_CEIL  RMSE_CEIL  MAE_CEIL\n",
      "1  Auto ARIMA  0.1634  0.1729  3.2829  4.5522  0.0778  0.0745  0.9503  0.9500    4.5662   3.2833   0.9471     4.6957    3.3833\n",
      "0       ARIMA  0.2924  0.2744  5.8763  7.2233  0.1446  0.1264  0.8749  0.8738    7.2549   5.8667   0.8642     7.5266    6.2500\n"
     ]
    }
   ],
   "source": [
    "output_excel_path = os.path.join(DATAFRAME_SPECIFIC_PATH, 'model_performance_metrics.xlsx')\n",
    "print(f\"Saving performance metrics to: {output_excel_path}\")\n",
    "\n",
    "with pd.ExcelWriter(output_excel_path) as writer:\n",
    "    # --- Process and Save Base Model Metrics ---\n",
    "    if holdout_predictions_metric:\n",
    "        list_of_metric_dfs_base = []\n",
    "        for model_name, metrics_df in holdout_predictions_metric.items():\n",
    "            list_of_metric_dfs_base.append(metrics_df)\n",
    "        \n",
    "        results_df_base = pd.concat(list_of_metric_dfs_base, ignore_index=True).sort_values('R2', ascending=False)\n",
    "        print(\"\\n--- Base Model Holdout Predictions ---\")\n",
    "        print(results_df_base.to_string())\n",
    "        results_df_base.to_excel(writer, sheet_name='Base Model Metrics', index=False)\n",
    "    else:\n",
    "        print(\"\\nNo base model metrics to save.\")\n",
    "\n",
    "    # --- Process and Save Tuned Model Metrics ---\n",
    "    if tuning_predictions_metric:\n",
    "        list_of_metric_dfs_tuned = []\n",
    "        for model_name, metrics_df in tuning_predictions_metric.items():\n",
    "            list_of_metric_dfs_tuned.append(metrics_df)\n",
    "            \n",
    "        results_df_tuned = pd.concat(list_of_metric_dfs_tuned, ignore_index=True).sort_values('R2', ascending=False)\n",
    "        print(\"\\n--- Tuned Model Holdout Predictions ---\")\n",
    "        print(results_df_tuned.to_string())\n",
    "        results_df_tuned.to_excel(writer, sheet_name='Tuned Model Metrics', index=False)\n",
    "    else:\n",
    "        print(\"\\nNo tuned model metrics to save.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
